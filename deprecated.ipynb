{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models for Replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama 2 chat (instruction-tuned + fine-tuned on chat dialogues)\n",
    "LLAMA2_70B_CHAT = \"meta/llama-2-70b-chat:2d19859030ff705a87c746f7e96eea03aefb71f166725aee39692f1476566d48\"\n",
    "LLAMA2_13B_CHAT = \"meta/llama-2-13b-chat:6b4da803a2382c08868c5af10a523892f38e2de1aafb2ee55b020d9efef2fdb8\"\n",
    "\n",
    "# instruction-tuned mistral \n",
    "MIXTRAL_8X7B_INSTRUCT_V01 = \"mistralai/mixtral-8x7b-instruct-v0.1:7b3212fbaf88310cfef07a061ce94224e82efc8403c26fc67e8f6c065de51f21\" # not clear which version most recent | sparse Mixture of Experts, outperforms llama2-70b on several benchamrks\n",
    "MISTRAL_INSTRUCT_V02 = \"mistralai/mistral-7b-instruct-v0.2:f5701ad84de5715051cb99d550539719f8a7fbcf65e0e62a3d1eb3f94720764e\"\n",
    "\n",
    "# instruction-tuned gemma\n",
    "GEMMA_7B_IT = \"cjwbw/gemma-7b-it:2790a695e5dcae15506138cc4718d1106d0d475e6dca4b1d43f42414647993d5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama2 70b\n",
    "s2a = reload(s2a)\n",
    "#model_preds = s2a.run_model_replicate(LLAMA2_70B_CHAT, zero_attr_sents, zero_attr_targets, system_prompt, out=True, file_spec='zero_attr_llama_70b', post_processing=True)\n",
    "#acc = s2a.accuracy(model_preds, zero_attr_targets)\n",
    "print(f\"Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# mistral\n",
    "model_preds = s2a.run_model_replicate(MIXTRAL_8X7B_INSTRUCT_V01, zero_attr_sents, zero_attr_targets, system_prompt, out=True, file_spec='zero_attr_mistral8x7bv01', post_processing=True)\n",
    "acc = s2a.accuracy(model_preds, zero_attr_targets)\n",
    "print(f\"Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "sents = list(multiSem['sentence'][:N])\n",
    "targets = list(multiSem['target_occupation'][:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89\n"
     ]
    }
   ],
   "source": [
    "s2a = reload(s2a)\n",
    "model_preds = s2a.run_r_llama(LLAMA2_70B_CHAT, sents, targets, system_prompt, out=True, file_spec='first100_llama_70b')\n",
    "model_preds = s2a.post_proc(model_preds)\n",
    "acc = s2a.accuracy(model_preds, targets)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta/llama-2-70b-chat:2d19859030ff705a87c746f7e96eea03aefb71f166725aee39692f1476566d48\n"
     ]
    }
   ],
   "source": [
    "pred = s2a.run_r_llama_instance(LLAMA2_70B_CHAT, \"Daniel has a sister , played basketball , sang in a choir and now works as a butcher , Joe works as a painter , John works as a fisherman , and Rowan works as a florist . For his job , Daniel sells\", system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', ' meat']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Complete the following sentence with one single word: Daniel works as a florist . For his job , Daniel sells'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = system_prompt + prompt\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ____ .\n",
      "\n",
      "The answer is flowers.\n",
      "\n",
      "Daniel works as a florist. For his job, Daniel sells flowers."
     ]
    }
   ],
   "source": [
    "s2a = reload(s2a)\n",
    "\n",
    "s2a.run_r_gemma(prompt, model=GEMMA_7B_IT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. fresh flowers and potted plants,\n",
      "\n",
      "2. arranges and designs flower bouquets and centerpieces for various occasions,\n",
      "3. provides flower delivery services, and\n",
      "4. assists customers with selecting the right flowers and plants for their needs.\n",
      "\n",
      "Daniel's job as a florist involves a lot of customer interaction, creativity, and attention to detail. He may work in a retail flower shop, a garden center, or even run his own business. Florists often have to source their flowers from wholesalers or farms, and may also handle tasks such as watering, pruning, and arranging the flowers in the shop. They may work long hours leading up to holidays and special occasions, as these are often the busiest times for the floristry business."
     ]
    }
   ],
   "source": [
    "s2a = reload(s2a)\n",
    "\n",
    "s2a.run_r_mistral(prompt, model=MISTRAL_INSTRUCT_V02)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
